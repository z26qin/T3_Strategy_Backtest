{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin News Summarization (LangChain + RAG)\n",
    "\n",
    "This notebook fetches Bitcoin news from the last 24 hours, processes them through a RAG pipeline using LangChain, and outputs an LLM-generated summary of the most important factors driving Bitcoin price movement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages\n!pip install -q langchain langchain-ollama langchain-community chromadb requests duckduckgo-search langgraph"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nimport hashlib\nimport time\nimport requests\nimport pandas as pd\nimport yfinance as yf\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom pathlib import Path\nfrom datetime import datetime, timedelta, timezone\nfrom IPython.display import display, Markdown\n\nfrom langchain.schema import Document\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_ollama import OllamaEmbeddings, ChatOllama\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate\nfrom langchain_community.tools import DuckDuckGoSearchRun\nfrom langchain.tools import Tool\nfrom langchain.agents import create_react_agent, AgentExecutor"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# --- Configuration ---\nNEWS_LOOKBACK_HOURS = 24\nTOP_K_ARTICLES = 10  # Retrieve top-K relevant docs for summarization\n\n# Ollama model configuration (runs locally, no API keys needed for LLM)\nOLLAMA_BASE_URL = \"http://localhost:11434\"  # Default Ollama server\nLLM_MODEL = \"qwen2.5:7b\"\nEMBEDDING_MODEL = \"nomic-embed-text\"\n\n# News API key (optional — falls back to CryptoPanic if not set)\nNEWSAPI_KEY = os.environ.get(\"NEWSAPI_KEY\")\n\n# Verification agent cache directory\nVERIFICATION_CACHE_DIR = Path(\"./cache\")\nVERIFICATION_CACHE_DIR.mkdir(exist_ok=True)\n\nprint(\"Configuration loaded.\")\nprint(f\"  News lookback: {NEWS_LOOKBACK_HOURS} hours\")\nprint(f\"  Top-K articles for retrieval: {TOP_K_ARTICLES}\")\nprint(f\"  LLM: {LLM_MODEL} (via Ollama)\")\nprint(f\"  Embeddings: {EMBEDDING_MODEL} (via Ollama)\")\nprint(f\"  NEWSAPI_KEY: {'set' if NEWSAPI_KEY else 'not set (will use CryptoPanic fallback)'}\")\nprint(f\"  Verification cache: {VERIFICATION_CACHE_DIR.resolve()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Collection — News APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_newsapi_articles(api_key: str, lookback_hours: int) -> list[dict]:\n",
    "    \"\"\"Fetch Bitcoin news from NewsAPI.org.\"\"\"\n",
    "    from_time = datetime.now(timezone.utc) - timedelta(hours=lookback_hours)\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": \"bitcoin OR BTC OR cryptocurrency\",\n",
    "        \"from\": from_time.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "        \"language\": \"en\",\n",
    "        \"pageSize\": 50,\n",
    "        \"apiKey\": api_key,\n",
    "    }\n",
    "    resp = requests.get(url, params=params, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    articles = []\n",
    "    for art in data.get(\"articles\", []):\n",
    "        articles.append({\n",
    "            \"title\": art.get(\"title\", \"\"),\n",
    "            \"description\": art.get(\"description\", \"\") or \"\",\n",
    "            \"content\": art.get(\"content\", \"\") or art.get(\"description\", \"\") or \"\",\n",
    "            \"source\": art.get(\"source\", {}).get(\"name\", \"Unknown\"),\n",
    "            \"publishedAt\": art.get(\"publishedAt\", \"\"),\n",
    "            \"url\": art.get(\"url\", \"\"),\n",
    "        })\n",
    "    return articles\n",
    "\n",
    "\n",
    "def fetch_cryptopanic_articles(lookback_hours: int) -> list[dict]:\n",
    "    \"\"\"Fetch Bitcoin news from CryptoPanic (free, no key needed for basic access).\"\"\"\n",
    "    url = \"https://cryptopanic.com/api/free/v1/posts/\"\n",
    "    params = {\n",
    "        \"currencies\": \"BTC\",\n",
    "        \"kind\": \"news\",\n",
    "        \"public\": \"true\",\n",
    "    }\n",
    "    resp = requests.get(url, params=params, timeout=15)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    cutoff = datetime.now(timezone.utc) - timedelta(hours=lookback_hours)\n",
    "    articles = []\n",
    "    for post in data.get(\"results\", []):\n",
    "        published = post.get(\"published_at\", \"\")\n",
    "        if published:\n",
    "            pub_dt = datetime.fromisoformat(published.replace(\"Z\", \"+00:00\"))\n",
    "            if pub_dt < cutoff:\n",
    "                continue\n",
    "        articles.append({\n",
    "            \"title\": post.get(\"title\", \"\"),\n",
    "            \"description\": post.get(\"title\", \"\"),\n",
    "            \"content\": post.get(\"title\", \"\"),\n",
    "            \"source\": post.get(\"source\", {}).get(\"title\", \"CryptoPanic\"),\n",
    "            \"publishedAt\": published,\n",
    "            \"url\": post.get(\"url\", \"\"),\n",
    "        })\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch articles: try NewsAPI first, fall back to CryptoPanic\n",
    "articles = []\n",
    "\n",
    "if NEWSAPI_KEY:\n",
    "    try:\n",
    "        articles = fetch_newsapi_articles(NEWSAPI_KEY, NEWS_LOOKBACK_HOURS)\n",
    "        print(f\"Fetched {len(articles)} articles from NewsAPI.\")\n",
    "    except Exception as e:\n",
    "        print(f\"NewsAPI failed: {e}. Trying CryptoPanic fallback...\")\n",
    "\n",
    "if not articles:\n",
    "    try:\n",
    "        articles = fetch_cryptopanic_articles(NEWS_LOOKBACK_HOURS)\n",
    "        print(f\"Fetched {len(articles)} articles from CryptoPanic.\")\n",
    "    except Exception as e:\n",
    "        print(f\"CryptoPanic also failed: {e}\")\n",
    "\n",
    "if not articles:\n",
    "    raise RuntimeError(\"No articles fetched from any source. Check API keys and connectivity.\")\n",
    "\n",
    "# Show sample\n",
    "df_articles = pd.DataFrame(articles)\n",
    "print(f\"\\nTotal articles: {len(df_articles)}\")\n",
    "df_articles[[\"title\", \"source\", \"publishedAt\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 3.5 News Verification Agent\n\nUses a ReAct agent with DuckDuckGo search to cross-validate fetched headlines against other web sources. Articles that can't be corroborated are dropped before entering the RAG pipeline. Results are cached daily to avoid redundant API calls.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# --- Verification Agent Setup ---\n\n# Initialize LLM for the agent\nverification_llm = ChatOllama(\n    model=LLM_MODEL,\n    base_url=OLLAMA_BASE_URL,\n    temperature=0.1,\n)\n\n# Web search tool (free, no API key required)\nsearch_tool = DuckDuckGoSearchRun()\n\ntools = [\n    Tool(\n        name=\"Web_Search\",\n        func=search_tool.run,\n        description=\"Search the web using DuckDuckGo to find corroborating news sources for a headline.\",\n    ),\n]\n\n# ReAct agent prompt for fact-checking\nVERIFICATION_AGENT_PROMPT = PromptTemplate.from_template(\n    \"\"\"You are a fact-checking assistant. Your job is to verify whether a news headline\nis reported by other credible sources.\n\nYou have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: the headline to verify\nThought: I need to search for this headline to see if other sources report it\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat at most 2 times)\nThought: I now have enough information to make a verdict\nFinal Answer: a JSON object with \"status\" and \"reason\" keys\n\nThe \"status\" must be one of:\n- \"verified\": Multiple sources confirm this news\n- \"uncertain\": Limited info, but no contradictions found\n- \"unverified\": Cannot find corroboration or contradicts known facts\n\nQuestion: {input}\nThought: {agent_scratchpad}\"\"\"\n)\n\n# Create the agent\nverification_agent = create_react_agent(verification_llm, tools, VERIFICATION_AGENT_PROMPT)\nagent_executor = AgentExecutor(\n    agent=verification_agent,\n    tools=tools,\n    verbose=False,\n    max_iterations=3,\n    handle_parsing_errors=True,\n)\n\nprint(\"Verification agent initialized.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --- Run Verification (with daily cache) ---\n\ncache_file = VERIFICATION_CACHE_DIR / f\"verified_articles_{datetime.now().strftime('%Y-%m-%d')}.json\"\n\nif cache_file.exists():\n    # Cache hit: load previous results\n    with open(cache_file, \"r\") as f:\n        verification_results = json.load(f)\n    print(f\"Loaded cached verification results from {cache_file.name}\")\n    print(f\"  ({len(verification_results)} articles previously verified)\")\nelse:\n    # Cache miss: run verification agent\n    print(f\"No cache for today. Running verification agent on {len(articles)} articles...\")\n    verification_results = []\n    batch_size = 5\n\n    for i in range(0, len(articles), batch_size):\n        batch = articles[i:i + batch_size]\n        print(f\"  Verifying batch {i // batch_size + 1}/{(len(articles) - 1) // batch_size + 1}...\")\n\n        for art in batch:\n            headline = art[\"title\"]\n            if not headline:\n                verification_results.append({\n                    \"title\": headline,\n                    \"status\": \"unverified\",\n                    \"reason\": \"Empty headline\",\n                })\n                continue\n\n            try:\n                result = agent_executor.invoke({\"input\": headline})\n                output = result.get(\"output\", \"\")\n\n                # Parse agent's JSON response\n                try:\n                    # Try to extract JSON from the output\n                    if \"{\" in output and \"}\" in output:\n                        json_str = output[output.index(\"{\"):output.rindex(\"}\") + 1]\n                        verdict = json.loads(json_str)\n                    else:\n                        verdict = {\"status\": \"uncertain\", \"reason\": output[:200]}\n                except (json.JSONDecodeError, ValueError):\n                    verdict = {\"status\": \"uncertain\", \"reason\": output[:200]}\n\n                verification_results.append({\n                    \"title\": headline,\n                    \"status\": verdict.get(\"status\", \"uncertain\"),\n                    \"reason\": verdict.get(\"reason\", \"No reason provided\"),\n                })\n            except Exception as e:\n                # On agent failure, default to uncertain (don't drop the article)\n                verification_results.append({\n                    \"title\": headline,\n                    \"status\": \"uncertain\",\n                    \"reason\": f\"Agent error: {str(e)[:100]}\",\n                })\n\n        # Brief pause between batches to avoid rate limits\n        if i + batch_size < len(articles):\n            time.sleep(2)\n\n    print(f\"Verification complete for {len(verification_results)} articles.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --- Filter Articles & Save Cache ---\n\n# Build a lookup of verification status by title\nstatus_by_title = {r[\"title\"]: r[\"status\"] for r in verification_results}\n\n# Filter: keep only verified or uncertain articles\noriginal_count = len(articles)\narticles = [\n    art for art in articles\n    if status_by_title.get(art[\"title\"], \"uncertain\") in (\"verified\", \"uncertain\")\n]\n\n# Count verdicts\nn_verified = sum(1 for r in verification_results if r[\"status\"] == \"verified\")\nn_uncertain = sum(1 for r in verification_results if r[\"status\"] == \"uncertain\")\nn_unverified = sum(1 for r in verification_results if r[\"status\"] == \"unverified\")\n\n# Save cache (only if we actually ran the agent, not loaded from cache)\nif not cache_file.exists():\n    with open(cache_file, \"w\") as f:\n        json.dump(verification_results, f, indent=2)\n    print(f\"Cache saved to {cache_file.name}\")\n\n# Print summary\nprint(f\"\\nVerification Summary:\")\nprint(f\"  Verified:   {n_verified}/{original_count}\")\nprint(f\"  Uncertain:  {n_uncertain}/{original_count}\")\nprint(f\"  Unverified: {n_unverified}/{original_count} (dropped)\")\nprint(f\"\\n  Articles passed to RAG pipeline: {len(articles)}/{original_count}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BTC Price Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch last 24h BTC price from yfinance (1-hour interval)\n",
    "btc = yf.Ticker(\"BTC-USD\")\n",
    "btc_hist = btc.history(period=\"2d\", interval=\"1h\")\n",
    "\n",
    "# Calculate metrics\n",
    "current_price = btc_hist[\"Close\"].iloc[-1]\n",
    "price_24h_ago = btc_hist[\"Close\"].iloc[-24] if len(btc_hist) >= 24 else btc_hist[\"Close\"].iloc[0]\n",
    "change_pct = ((current_price - price_24h_ago) / price_24h_ago) * 100\n",
    "high_24h = btc_hist[\"Close\"].tail(24).max()\n",
    "low_24h = btc_hist[\"Close\"].tail(24).min()\n",
    "\n",
    "price_context = {\n",
    "    \"current_price\": current_price,\n",
    "    \"change_pct\": change_pct,\n",
    "    \"high_24h\": high_24h,\n",
    "    \"low_24h\": low_24h,\n",
    "}\n",
    "\n",
    "print(f\"BTC Current Price: ${current_price:,.2f}\")\n",
    "print(f\"24h Change: {change_pct:+.2f}%\")\n",
    "print(f\"24h High: ${high_24h:,.2f}\")\n",
    "print(f\"24h Low: ${low_24h:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 1: Convert articles to LangChain Document objects\ndocuments = []\nfor art in articles:\n    text = f\"{art['title']}\\n\\n{art['content']}\"\n    metadata = {\n        \"source\": art[\"source\"],\n        \"publishedAt\": art[\"publishedAt\"],\n        \"url\": art[\"url\"],\n        \"title\": art[\"title\"],\n    }\n    documents.append(Document(page_content=text, metadata=metadata))\n\nprint(f\"Created {len(documents)} Document objects.\")\n\n# Step 2: Text Splitting\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200,\n    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n)\nchunks = text_splitter.split_documents(documents)\nprint(f\"Split into {len(chunks)} chunks.\")\n\n# Step 3: Embeddings + Vector Store (ChromaDB, ephemeral/in-memory)\nembeddings = OllamaEmbeddings(\n    model=EMBEDDING_MODEL,\n    base_url=OLLAMA_BASE_URL,\n)\nvectorstore = Chroma.from_documents(\n    documents=chunks,\n    embedding=embeddings,\n)\nprint(f\"Vector store created with {vectorstore._collection.count()} vectors.\")\n\n# Step 4: Retriever\nretriever = vectorstore.as_retriever(\n    search_type=\"similarity\",\n    search_kwargs={\"k\": TOP_K_ARTICLES},\n)\nprint(f\"Retriever configured (top-{TOP_K_ARTICLES} similarity search).\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LLM Summarization Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Custom prompt template\nSUMMARY_PROMPT_TEMPLATE = \"\"\"You are a crypto market analyst. Based on the following news articles \\\nfrom the last 24 hours, provide:\n\n1. **Market Summary**: 1-2 sentence overview of Bitcoin's movement\n2. **Key Drivers**: Top 3-5 factors driving price (bullish/bearish)\n3. **Sentiment**: Overall market sentiment (Bullish/Neutral/Bearish)\n4. **Notable Events**: Any major events (regulatory, institutional, technical)\n5. **Outlook**: Brief forward-looking view based on current news\n\nContext: BTC is currently at ${price}, {change}% in last 24h (High: ${high}, Low: ${low}).\n\nArticles:\n{context}\n\nQuestion: {question}\n\"\"\"\n\nprompt = PromptTemplate(\n    template=SUMMARY_PROMPT_TEMPLATE,\n    input_variables=[\"context\", \"question\"],\n    partial_variables={\n        \"price\": f\"{current_price:,.2f}\",\n        \"change\": f\"{change_pct:+.2f}\",\n        \"high\": f\"{high_24h:,.2f}\",\n        \"low\": f\"{low_24h:,.2f}\",\n    },\n)\n\n# LLM (Ollama - runs locally)\nllm = ChatOllama(\n    model=LLM_MODEL,\n    base_url=OLLAMA_BASE_URL,\n    temperature=0.3,\n)\n\n# RetrievalQA chain\nqa_chain = RetrievalQA.from_chain_type(\n    llm=llm,\n    chain_type=\"stuff\",\n    retriever=retriever,\n    chain_type_kwargs={\"prompt\": prompt},\n    return_source_documents=True,\n)\n\nprint(\"Summarization chain ready.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the summarization\n",
    "query = \"Summarize the key Bitcoin news and market drivers from the last 24 hours.\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "summary_text = result[\"result\"]\n",
    "source_docs = result[\"source_documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Output Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display formatted summary\n",
    "display(Markdown(\"# Bitcoin News Summary (Last 24 Hours)\\n\"))\n",
    "display(Markdown(summary_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source articles table\n",
    "display(Markdown(\"## Source Articles\"))\n",
    "\n",
    "source_data = []\n",
    "seen_titles = set()\n",
    "for doc in source_docs:\n",
    "    title = doc.metadata.get(\"title\", \"N/A\")\n",
    "    if title in seen_titles:\n",
    "        continue\n",
    "    seen_titles.add(title)\n",
    "    source_data.append({\n",
    "        \"Title\": title,\n",
    "        \"Source\": doc.metadata.get(\"source\", \"N/A\"),\n",
    "        \"Published\": doc.metadata.get(\"publishedAt\", \"N/A\")[:16],\n",
    "        \"URL\": doc.metadata.get(\"url\", \"\"),\n",
    "    })\n",
    "\n",
    "df_sources = pd.DataFrame(source_data)\n",
    "display(df_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BTC 24h price chart\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "plot_data = btc_hist.tail(24)\n",
    "ax.plot(plot_data.index, plot_data[\"Close\"], color=\"orange\", linewidth=2, label=\"BTC Price\")\n",
    "ax.fill_between(plot_data.index, plot_data[\"Low\"], plot_data[\"High\"], alpha=0.1, color=\"orange\")\n",
    "\n",
    "ax.set_title(\"BTC-USD Last 24 Hours\", fontsize=14, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Time (UTC)\")\n",
    "ax.set_ylabel(\"Price (USD)\")\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m/%d %H:%M\"))\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Annotate current price\n",
    "ax.annotate(\n",
    "    f\"${current_price:,.0f}\",\n",
    "    xy=(plot_data.index[-1], current_price),\n",
    "    xytext=(10, 10),\n",
    "    textcoords=\"offset points\",\n",
    "    fontsize=11,\n",
    "    fontweight=\"bold\",\n",
    "    color=\"darkorange\",\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sentiment Analysis (Bonus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Classify each headline as Bullish/Neutral/Bearish using the LLM\nSENTIMENT_PROMPT = \"\"\"Classify the sentiment of each Bitcoin news headline below as \\\nexactly one of: Bullish, Neutral, or Bearish.\n\nReturn ONLY a JSON array of objects with \"title\" and \"sentiment\" keys.\n\nHeadlines:\n{headlines}\n\"\"\"\n\n# Take up to 20 headlines for classification\nheadlines_for_sentiment = [art[\"title\"] for art in articles[:20] if art[\"title\"]]\nheadlines_text = \"\\n\".join(f\"- {h}\" for h in headlines_for_sentiment)\n\nsentiment_response = llm.invoke(SENTIMENT_PROMPT.format(headlines=headlines_text))\n\n# Parse sentiment results\ntry:\n    # Extract JSON from response\n    response_text = sentiment_response.content\n    # Handle potential markdown code blocks in response\n    if \"```json\" in response_text:\n        response_text = response_text.split(\"```json\")[1].split(\"```\")[0]\n    elif \"```\" in response_text:\n        response_text = response_text.split(\"```\")[1].split(\"```\")[0]\n    sentiment_results = json.loads(response_text.strip())\n    df_sentiment = pd.DataFrame(sentiment_results)\n    print(f\"Classified {len(df_sentiment)} headlines.\")\nexcept (json.JSONDecodeError, IndexError) as e:\n    print(f\"Failed to parse sentiment response: {e}\")\n    print(\"Raw response:\", sentiment_response.content[:500])\n    df_sentiment = pd.DataFrame(columns=[\"title\", \"sentiment\"])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment distribution pie chart\n",
    "if not df_sentiment.empty:\n",
    "    sentiment_counts = df_sentiment[\"sentiment\"].value_counts()\n",
    "\n",
    "    colors = {\n",
    "        \"Bullish\": \"#2ecc71\",\n",
    "        \"Neutral\": \"#95a5a6\",\n",
    "        \"Bearish\": \"#e74c3c\",\n",
    "    }\n",
    "    pie_colors = [colors.get(s, \"#bdc3c7\") for s in sentiment_counts.index]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Pie chart\n",
    "    axes[0].pie(\n",
    "        sentiment_counts.values,\n",
    "        labels=sentiment_counts.index,\n",
    "        colors=pie_colors,\n",
    "        autopct=\"%1.0f%%\",\n",
    "        startangle=90,\n",
    "        textprops={\"fontsize\": 12},\n",
    "    )\n",
    "    axes[0].set_title(\"News Sentiment Distribution\", fontsize=13, fontweight=\"bold\")\n",
    "\n",
    "    # Price chart with sentiment overlay\n",
    "    axes[1].plot(plot_data.index, plot_data[\"Close\"], color=\"orange\", linewidth=2)\n",
    "    axes[1].set_title(\"BTC Price with Sentiment Context\", fontsize=13, fontweight=\"bold\")\n",
    "    axes[1].set_xlabel(\"Time (UTC)\")\n",
    "    axes[1].set_ylabel(\"Price (USD)\")\n",
    "\n",
    "    # Add sentiment annotation\n",
    "    dominant = sentiment_counts.index[0] if len(sentiment_counts) > 0 else \"Neutral\"\n",
    "    bg_color = colors.get(dominant, \"#bdc3c7\")\n",
    "    axes[1].axhspan(\n",
    "        plot_data[\"Close\"].min(), plot_data[\"Close\"].max(),\n",
    "        alpha=0.08, color=bg_color, label=f\"Dominant: {dominant}\"\n",
    "    )\n",
    "    axes[1].legend(fontsize=11)\n",
    "    axes[1].xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Display sentiment table\n",
    "    display(Markdown(\"### Headline Sentiments\"))\n",
    "    display(df_sentiment)\n",
    "else:\n",
    "    print(\"No sentiment data to display.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}